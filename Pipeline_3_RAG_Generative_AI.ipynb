{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFLLl1Agum8O"
      },
      "source": [
        "# Pipeline 3: A RAG Pinecone vector store for Generative AI\n",
        "\n",
        "copyright 2024, Denis Rothman\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Installing the environment"
      ],
      "metadata": {
        "id": "8QGI1D8FVrT6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoCE_RrKVrT7",
        "outputId": "e8d2355e-f261-44d7-cfcd-e423c9f377a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#API Key\n",
        "#Store you key in a file and read it(you can type it directly in the notebook but it will be visible for somebody next to you)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bedcc764-1ef8-4e57-96df-ad31685fc509",
        "id": "Z2abuU9OkVFL"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==1.40.3\n",
            "  Downloading openai-1.40.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.40.3) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.40.3) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai==1.40.3)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai==1.40.3)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.40.3) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.40.3) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.40.3) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai==1.40.3) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.40.3) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.40.3) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.40.3) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai==1.40.3)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.40.3)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.40.3) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.40.3) (2.20.1)\n",
            "Downloading openai-1.40.3-py3-none-any.whl (360 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m360.7/360.7 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jiter-0.5.0 openai-1.40.3\n",
            "Collecting pinecone-client==5.0.1\n",
            "  Downloading pinecone_client-5.0.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==5.0.1) (2024.7.4)\n",
            "Collecting pinecone-plugin-inference<2.0.0,>=1.0.3 (from pinecone-client==5.0.1)\n",
            "  Downloading pinecone_plugin_inference-1.0.3-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone-client==5.0.1)\n",
            "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==5.0.1) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==5.0.1) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==5.0.1) (2.0.7)\n",
            "Downloading pinecone_client-5.0.1-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_inference-1.0.3-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.6/117.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
            "Installing collected packages: pinecone-plugin-interface, pinecone-plugin-inference, pinecone-client\n",
            "Successfully installed pinecone-client-5.0.1 pinecone-plugin-inference-1.0.3 pinecone-plugin-interface-0.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==1.40.3\n",
        "!pip install pinecone-client==5.0.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"drive/MyDrive/files/pinecone.txt\", \"r\")\n",
        "PINECONE_API_KEY=f.readline()\n",
        "f.close()"
      ],
      "metadata": {
        "id": "xotquvXHRxrU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"drive/MyDrive/files/api_key.txt\", \"r\")\n",
        "API_KEY=f.readline()\n",
        "f.close()"
      ],
      "metadata": {
        "id": "I8lwM8XMd9bz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The OpenAI Key\n",
        "import os\n",
        "import openai\n",
        "os.environ['OPENAI_API_KEY'] =API_KEY\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "UbKxUEHiZNyX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  The Pinecone index"
      ],
      "metadata": {
        "id": "XswfiN5Z1OvT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "nOSA_Spit_xq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
        "api_key = os.environ.get('PINECONE_API_KEY') or 'PINECONE_API_KEY'\n",
        "\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "P---PNLpXeQs"
      },
      "outputs": [],
      "source": [
        "from pinecone import ServerlessSpec\n",
        "\n",
        "index_name = 'bank-index-50000'\n",
        "cloud = os.environ.get('PINECONE_CLOUD') or 'aws'\n",
        "region = os.environ.get('PINECONE_REGION') or 'us-east-1'\n",
        "\n",
        "spec = ServerlessSpec(cloud=cloud, region=region)"
      ]
    },
    {
      "source": [
        "import time\n",
        "import pinecone\n",
        "# check if index already exists (it shouldn't if this is first time)\n",
        "if index_name not in pc.list_indexes().names():\n",
        "    # if does not exist, create index\n",
        "    pc.create_index(\n",
        "        index_name,\n",
        "        dimension=1536,  # dimensionality of text-embedding-ada-002\n",
        "        metric='cosine',\n",
        "        spec=spec\n",
        "    )\n",
        "    # wait for index to be initialized\n",
        "    time.sleep(1)\n",
        "\n",
        "# connect to index\n",
        "index = pc.Index(index_name)\n",
        "# view index stats\n",
        "index.describe_index_stats()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "jO7AYljM0gq1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2c83598-e789-4fc0-a04f-c1badb9d6092"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 1536,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {'': {'vector_count': 50000}},\n",
              " 'total_vector_count': 50000}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG with GPT-4o"
      ],
      "metadata": {
        "id": "7vfLjBF4G9rk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Query the dataset"
      ],
      "metadata": {
        "id": "7K_RLspI4MLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import time\n",
        "\n",
        "embedding_model = \"text-embedding-3-small\"\n",
        "\n",
        "# Initialize the OpenAI client\n",
        "client = openai.OpenAI()\n",
        "\n",
        "def get_embedding(text, model=embedding_model):\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    response = client.embeddings.create(input=[text], model=model)\n",
        "    embedding = response.data[0].embedding\n",
        "    return embedding"
      ],
      "metadata": {
        "id": "nKl3UiJ3-pXE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Querying a target vector"
      ],
      "metadata": {
        "id": "2qjzgj6XxDsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()  # Start timing before the request\n",
        "# Target vector\n",
        "query_text = \"Customer Henderson CreditScore 599 Age 37Tenure 2Balance 0.0NumOfProducts 1HasCrCard 1IsActiveMember 1EstimatedSalary 107000.88Exited 1Complain 1Satisfaction Score 2Card Type DIAMONDPoint Earned 501\"\n",
        "query_embedding = get_embedding(query_text,model=embedding_model)"
      ],
      "metadata": {
        "id": "n4Ev_TOZ6NBy"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform the query using the embedding\n",
        "query_results = index.query(\n",
        "    vector=query_embedding,\n",
        "    include_metadata=True,\n",
        "    top_k=1\n",
        ")\n",
        "# Print the query results along with metadata\n",
        "print(\"Query Results:\")\n",
        "for match in query_results['matches']:\n",
        "    print(f\"ID: {match['id']}, Score: {match['score']}\")\n",
        "    if 'metadata' in match and 'text' in match['metadata']:\n",
        "        print(f\"Text: {match['metadata']['text']}\")\n",
        "    else:\n",
        "        print(\"No metadata available.\")\n",
        "\n",
        "response_time = time.time() - start_time              # Measure response time\n",
        "print(f\"Querying response time: {response_time:.2f} seconds\")  # Print response time"
      ],
      "metadata": {
        "id": "-MkWhXEwF76b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da35e93a-c305-4a74-a4fe-dfb5653badfa"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query Results:\n",
            "ID: 46366, Score: 0.854999781\n",
            "Text: CustomerId: 15740160 CreditScore: 616 Age: 31 Tenure: 1 Balance: 0.0 NumOfProducts: 2 HasCrCard: 1 IsActiveMember: 1 EstimatedSalary: 54706.75 Exited: 0 Complain: 0 Satisfaction Score: 3 Card Type: DIAMOND Point Earned: 852\n",
            "Querying response time: 0.63 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract Relevant Texts"
      ],
      "metadata": {
        "id": "WajfbO2e4_fN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "relevant_texts = [match['metadata']['text'] for match in query_results['matches'] if 'metadata' in match and 'text' in match['metadata']]\n",
        "\n",
        "# Join all items in the list into a single string separated by a specific delimiter (e.g., a newline or space)\n",
        "combined_text = '\\n'.join(relevant_texts)  # Using newline as a separator for readability\n",
        "print(combined_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ClGVc5qUpPW",
        "outputId": "720f1929-71f6-4b6c-ef2c-c73c19b787ea"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CustomerId: 15740160 CreditScore: 616 Age: 31 Tenure: 1 Balance: 0.0 NumOfProducts: 2 HasCrCard: 1 IsActiveMember: 1 EstimatedSalary: 54706.75 Exited: 0 Complain: 0 Satisfaction Score: 3 Card Type: DIAMOND Point Earned: 852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Augmented prompt"
      ],
      "metadata": {
        "id": "2cBZowvcHJ5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine texts into a single string, separated by new lines\n",
        "combined_context = \"\\n\".join(relevant_texts)\n",
        "#prompt\n",
        "query_prompt=\"I have this customer bank record with interesting information on age, credit score and more and similar customers. What could I suggest to keep them in my bank in an email with an url to get new advantages based on the fields for each Customer ID:\"\n",
        "itext=query_prompt+ query_text+combined_context\n",
        "# Augmented input\n",
        "print(\"Prompt for the Generative AI model:\", itext)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac915bae-f30a-470c-8c62-61cf7bcc34e5",
        "id": "rmXVFInU4_fO"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt for the Generative AI model: I have this customer bank record with interesting information on age, credit score and more and similar customers. What could I suggest to keep them in my bank in an email with an url to get new advantages based on the fields for each Customer ID:Customer Henderson CreditScore 599 Age 37Tenure 2Balance 0.0NumOfProducts 1HasCrCard 1IsActiveMember 1EstimatedSalary 107000.88Exited 1Complain 1Satisfaction Score 2Card Type DIAMONDPoint Earned 501CustomerId: 15740160 CreditScore: 616 Age: 31 Tenure: 1 Balance: 0.0 NumOfProducts: 2 HasCrCard: 1 IsActiveMember: 1 EstimatedSalary: 54706.75 Exited: 0 Complain: 0 Satisfaction Score: 3 Card Type: DIAMOND Point Earned: 852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Augmented generation"
      ],
      "metadata": {
        "id": "QuF2PbYPbHtc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "gpt_model = \"gpt-4o\"\n",
        "\n",
        "import time\n",
        "start_time = time.time()  # Start timing before the request\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=gpt_model,\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You are the community manager can write engaging email based on the text you have. Do not use a surname but simply Dear Valued Customer instead.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": itext\n",
        "    }\n",
        "  ],\n",
        "  temperature=0,\n",
        "  max_tokens=300,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response.choices[0].message.content)\n",
        "\n",
        "response_time = time.time() - start_time              # Measure response time\n",
        "print(f\"Querying response time: {response_time:.2f} seconds\")  # Print response time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxXAdRdLNr26",
        "outputId": "f13a954d-9a79-4cbc-dbf3-4fb968646d68"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subject: Exclusive Benefits Await You at Our Bank!\n",
            "\n",
            "Dear Valued Customer,\n",
            "\n",
            "We hope this email finds you well. At our bank, we are constantly striving to enhance your banking experience and provide you with the best possible services. We have noticed that you are a valued customer with a DIAMOND card, and we would like to offer you some exclusive benefits tailored just for you!\n",
            "\n",
            "Based on your profile, we have identified several opportunities that could enhance your banking experience:\n",
            "\n",
            "1. **Personalized Financial Advice**: Our financial advisors are available to help you make the most of your finances. Whether it's planning for the future or managing your current assets, we are here to assist you.\n",
            "\n",
            "2. **Exclusive Rewards and Offers**: As a DIAMOND cardholder, you are eligible for special rewards and offers. Earn more points and enjoy exclusive discounts on various products and services.\n",
            "\n",
            "3. **Enhanced Credit Options**: With your current credit score, you may qualify for better credit options. We can help you explore these opportunities to improve your financial standing.\n",
            "\n",
            "4. **Complimentary Financial Health Check**: We understand the importance of financial well-being. Schedule a complimentary financial health check to ensure you are on the right track.\n",
            "\n",
            "5. **Loyalty Programs**: Participate in our loyalty programs and earn more points for every transaction. Redeem these points for exciting rewards and benefits.\n",
            "\n",
            "To explore these new advantages and more, please visit the following link: [Exclusive Benefits](https://www.yourbank\n",
            "Querying response time: 2.83 seconds\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}